<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " vocab="http://ogp.me/ns" lang="en">
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]--><!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]--><!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]--><!--[if gt IE 8]><!--><!--<![endif]--><head>
<meta charset="utf-8">
<!-- http://t.co/dKP3o1e --><meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Policy Gradient Methods: Part 1 | About Machines That Learn &amp; Think</title>
<link href="../../assets/css/rst.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/code.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/main.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/extra.css" rel="stylesheet" type="text/css">
<!-- Webfonts --><link href="https://fonts.googleapis.com/css?family=Maven+Pro" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Montserrat" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Anonymous+Pro" rel="stylesheet">
<!-- Load Modernizr --><script src="//mmistakes.github.io/hpstr-jekyll-theme/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script><script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script><link rel="alternate" type="application/rss+xml" title="RSS" href="../../rss.xml">
<link rel="canonical" href="http://ummavi.github.io/posts/policy-gradient-methods-part-1/">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'center', // Change this to 'center' to center equations.
    "HTML-CSS": {
        linebreaks: { automatic: true },
        styles: {'.MathJax_Display': {"margin": 0}},
    }
});
</script><!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Avinash Ummadisingu">
<link rel="prev" href="../introduction-to-reinforcement-learning/" title="Introduction to Reinforcement Learning" type="text/html">
<meta property="og:site_name" content="About Machines That Learn &amp; Think">
<meta property="og:title" content="Policy Gradient Methods: Part 1">
<meta property="og:url" content="http://ummavi.github.io/posts/policy-gradient-methods-part-1/">
<meta property="og:description" content="A few months ago, I attended the NIPS tutorial on Policy Optimization given by Pieter Abbeel and John Schulman hoping to better follow along all the new and exciting Policy Gradient based papers that ">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2017-03-01T22:03:39+01:00">
</head>
<body id="post-index" class="feature">
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>
    

    <nav id="dl-menu" class="dl-menuwrapper" role="navigation"><button class="dl-trigger">Open Menu</button>
    <ul class="dl-menu">
<li><a href="../../">Home</a></li>
            <li><a href="../../about/">About</a></li>
            <li><a href="../../the-reading-list/">Reading List</a></li>
            <li><a href="../../archive.html">Archive</a></li>
            <li><a href="../../categories/">Tags</a></li>
            <li><a href="../../rss.xml">RSS feed</a></li>
    
    
    </ul></nav><div class="entry-header">
      
  <div class="header-title">
    <div class="header-title-wrap">
    <img src="../../assets/img/sub_thin.png" width="400px/"><br><h3>About Machines That Learn &amp; Think</h3>
      <span class="header_social">
            <a href="mailto:u.avinash4x@gmail.com" target="_blank" rel="noopener noreferrer"><i class=" header_social_btn fa fa-fw fa-envelope-square"></i> </a>
            <a href="http://twitter.com/ummavi" target="_blank" rel="noopener noreferrer"><i class=" header_social_btn fa fa-fw fa-twitter-square"></i> </a>
            <a href="http://facebook.com/ummavi" target="_blank" rel="noopener noreferrer"><i class=" header_social_btn fa fa-fw fa-facebook-square"></i> </a>
            <a href="http://linkedin.com/in/avinashumm" target="_blank" rel="noopener noreferrer"><i class=" header_social_btn fa fa-fw fa-linkedin-square"></i> </a>
            <a href="http://github.com/ummavi" target="_blank" rel="noopener noreferrer"><i class=" header_social_btn fa fa-fw fa-github"></i> </a>
    </span>
    <span style="opacity: 0.0;float:left;width:172px "> <!-- Filler to center out the social media buttons-->  </span> 
    </div>
<!-- /.header-title-wrap -->
  </div>
<!-- /.header-title -->

</div>
<!-- /.entry-header -->

    <div id="main" role="main">
    	<div id="container" class="animated fadeIn">
            
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><div class="post-title">
        
    <h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Policy Gradient Methods: Part 1</a></h1>

        <div class="entry-meta">
            <span class="dateline"><a href="." rel="bookmark"><time class="published dt-published" datetime="2017-03-01T22:03:39+01:00" itemprop="datePublished" title="2017-03-01 22:03">2017-03-01 22:03</time></a></span>  ·  
                <span class="commentline">
        
    <a href="#disqus_thread" data-disqus-identifier="cache/posts/policy-gradient-methods-part-1.html">Comments</a>

</span>  ·  
        </div>

        <a class="btn zoombtn" href="../../">
            <i class="fa fa-chevron-left"></i>
        </a>
    </div>
</header><div class="e-content entry-content" itemprop="articleBody text">
    <div>
<p>A few months ago, I attended the NIPS tutorial on Policy Optimization given by Pieter Abbeel and John Schulman hoping to better follow along all the new and exciting Policy Gradient based papers that were coming out and getting to be State of the Art (SOTA) on a number of benchmarks. It started out well but I soon got lost in the math. Here's my attempt at looking through all of these methods again and try to understand them.</p>
<p>First, what's the whole idea behind them? Rather than computing a value function (like we did in the previous post that covered Value Functions) and using that to compute a policy $\pi$, we directly try to learn the policy. Well, cool! Why did we need to bother with the Value functions if we could just learn the policy directly? It turns out that Policy Gradient Methods are <em>much</em> harder to train well and hence not as popular as Value Function based methods. However, this seems set to change with a lot of great methods coming out with some very impressive results.</p>
<p>There's certain cases where approximating the Action-Value Function is a lot simpler than estimating a Policy. For others, it's a lot easier to estimate the policy directly.  Policy Gradient methods are capable of learning Stochastic policies which Action-Value based methods are not. This is crutial in games of imperfect information (where you can't fully observe everything) like a game of poker. </p>
<p>The reason I found Policy Gradient methods so hard to grasp initially is because we no longer "tell" the function approximator exactly what the value it should predict is as in the case of Value Function based methods. Instead we always tell it to adjust the action predicted towards something that gives it a more reward. Put another way, it changes from a supervised learning method to an optimization method. </p>
<p>Now, the distinction is still rather subtle. We still calculate a cumulative reward measure (A value function perhaps) for both methods but we don't use it to pick an action for the Policy Gradient methods. We only use it during training in order to tweak the probability some action is to be taken. </p>
</div>
    </div>
    <aside class="postpromonav"><nav><ul class="pager hidden-print">
<li class="previous">
                <a href="../introduction-to-reinforcement-learning/" rel="prev" title="Introduction to Reinforcement Learning">Previous post</a>
            </li>
        </ul></nav></aside><section class="comments"><h2>Comments</h2>
        
        
        <div id="disqus_thread"></div>
        <script>
        var disqus_shortname ="ummavi",
            disqus_url="http://ummavi.github.io/posts/policy-gradient-methods-part-1/",
        disqus_title="Policy Gradient Methods: Part 1",
        disqus_identifier="cache/posts/policy-gradient-methods-part-1.html",
        disqus_config = function () {
            this.language = "en";
        };
        (function() {
            var dsq = document.createElement('script'); dsq.async = true;
            dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a>
</noscript>
    <a href="https://disqus.com" class="dsq-brlink" rel="nofollow">Comments powered by <span class="logo-disqus">Disqus</span></a>


        </section></article><script>var disqus_shortname="ummavi";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script>
</div>
    </div>
    
    <div class="footer-wrapper">
        <footer role="contentinfo"><p>Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a> </p>
            
        </footer>
</div>

    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-89947234-1', 'auto');
  ga('send', 'pageview');

</script><script src="../../assets/js/scripts.min.js"></script><script src="../../assets/js/footnotes.js"></script><script>
    $(document).ready(function() {
    // zoom in/zoom out animations
    // if ($("#container").hasClass('fadeIn')) {
        // $("#container").removeClass("fadeIn").addClass("fadeOut");
    // }

    $(".btn").click(function() {
        $("#container").removeClass("fadeIn").addClass("fadeOut");
    });

        // Need this to show animation when go back in browser
        window.onunload = function() {};
    });
    </script>
</body>
</html>
